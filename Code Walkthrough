###Loading required packages & Datasets
library(RANN)
library(caret)
library(rattle)
training<-read.csv("pml-training.csv")
testing<-read.csv("pml-testing.csv")

str(training)

###Preprocessing Training data (Cleaning NAs, Retaining Non Zero Variables)
training[training=="NA"]<-NA
head(training)
training[training==""]<-NA
head(training)
str(training)

Kurt <- grep("^kurtosis.*", names(training))
Skew <- grep("^skewness.*", names(training))
Max <-grep("^max.*", names(training))
Min<-grep("^min.*", names(training))
Amp<-grep("^amplitude.*", names(training))
Var<-grep("^var.*", names(training))
Avg<-grep("^avg.*", names(training))
Std<-grep("^stddev.*", names(training))
training2<-(training[,-c(Kurt,Skew, Max, Min, Amp, Var, Avg, Std)])
training2<-training2[,-1] #removing serial number

###Splitting data for training & validation
set.seed(1010) 
splitset <- createDataPartition(training2$classe, p = 0.7, list = FALSE)
trainset <- training2[splitset, ]
validationset <- training2[-splitset, ]
str(trainset)
str(validationset)

###Executing PCA for variable reduction
trainset2<-preProcess(trainset[,-59], method = "pca", thresh = 0.85)
trainset3<-predict(trainset2, trainset)

###5 Fold Cross Validation
control <- trainControl(method = "cv", number = 5)

###Decision Tree
modrpart <- train(classe ~ ., data = trainset3, method = "rpart", trControl = control)
print(modrpart)

##Plotting Decision Tree
fancyRpartPlot(modrpart$finalModel)

validationsetpc<-predict(trainset2,validationset)
predictrpart<-predict(modrpart, validationsetpc)
accuracyrpart<-confusionMatrix(validationsetpc$classe,predictrpart)
accuracyrpart
#########################################Decision Tree Model Accuracy###############################################
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1451   92  120   11    0
         B  451  326  258  104    0
         C  285   42  620   77    2
         D  105    0  158  521  180
         E   53    0   70  270  689

Overall Statistics
                                          
               Accuracy : 0.6129          
                 95% CI : (0.6003, 0.6254)
    No Information Rate : 0.3985          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.5041          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.6188  0.70870   0.5057  0.53001   0.7910
Specificity            0.9370  0.85014   0.9129  0.90963   0.9216
Pos Pred Value         0.8668  0.28622   0.6043  0.54046   0.6368
Neg Pred Value         0.7877  0.97177   0.8753  0.90612   0.9621
Prevalence             0.3985  0.07816   0.2083  0.16703   0.1480
Detection Rate         0.2466  0.05540   0.1054  0.08853   0.1171
Detection Prevalence   0.2845  0.19354   0.1743  0.16381   0.1839
Balanced Accuracy      0.7779  0.77942   0.7093  0.71982   0.8563
#################################################################################################################

###Neural Network
modnnet<-train(classe ~ ., method = "nnet", data = trainset3, trControl = control)
print(modnnet)

predictnnet<-predict(modnnet, validationsetpc)
accuracynnet<-confusionMatrix(validationsetpc$classe, predictnnet)
accuracynnet
#########################################Neural Net Model Accuracy###############################################
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1531  107   34    0    2
         B  234  627  250   28    0
         C   25  176  808   17    0
         D    0   23  109  684  148
         E    0   12   17  400  653

Overall Statistics
                                          
               Accuracy : 0.7312          
                 95% CI : (0.7197, 0.7425)
    No Information Rate : 0.3042          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.6596          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.8553   0.6635   0.6634   0.6058   0.8132
Specificity            0.9651   0.8964   0.9533   0.9411   0.9156
Pos Pred Value         0.9146   0.5505   0.7875   0.7095   0.6035
Neg Pred Value         0.9385   0.9330   0.9156   0.9096   0.9688
Prevalence             0.3042   0.1606   0.2070   0.1918   0.1364
Detection Rate         0.2602   0.1065   0.1373   0.1162   0.1110
Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
Balanced Accuracy      0.9102   0.7799   0.8083   0.7735   0.8644
#################################################################################################################

###Random Forest

modrf<-train(classe ~ ., method = "rf", prox = TRUE, data = trainset3, trControl = control)
print(modrf)

predictrf<-predict(modrf, validationsetpc)
accuracyrf<-confusionMatrix(validationsetpc$classe, predictrf)
accuracyrf
#########################################Random Forest Model Accuracy############################################
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1648   14   12    0    0
         B   22 1107   10    0    0
         C    1   21 1000    4    0
         D    0    0   36  915   13
         E    0    0    1    6 1075

Overall Statistics
                                       
               Accuracy : 0.9762       
                 95% CI : (0.972, 0.98)
    No Information Rate : 0.2839       
    P-Value [Acc > NIR] : < 2.2e-16    
                                       
                  Kappa : 0.9699       
 Mcnemar's Test P-Value : NA           

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9862   0.9694   0.9443   0.9892   0.9881
Specificity            0.9938   0.9933   0.9946   0.9901   0.9985
Pos Pred Value         0.9845   0.9719   0.9747   0.9492   0.9935
Neg Pred Value         0.9945   0.9926   0.9879   0.9980   0.9973
Prevalence             0.2839   0.1941   0.1799   0.1572   0.1849
Detection Rate         0.2800   0.1881   0.1699   0.1555   0.1827
Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
Balanced Accuracy      0.9900   0.9813   0.9694   0.9897   0.9933
#################################################################################################################

###SVM
modsvm<-train(classe~., method = "svmRadial", tuneLength = 9, trControl = control, data= trainset3)
print(modsvm)

predictsvm<-predict(modsvm, validationsetpc)
accuracysvm<-confusionMatrix(validationsetpc$classe, predictsvm)
accuracysvm
################################################SVM Model Accuracy##############################################
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1651   17    6    0    0
         B   41 1083   15    0    0
         C    8   15 1001    2    0
         D    0    2   35  919    8
         E    0    0    0   20 1062

Overall Statistics
                                          
               Accuracy : 0.9713          
                 95% CI : (0.9667, 0.9754)
    No Information Rate : 0.2889          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9637          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9712   0.9696   0.9470   0.9766   0.9925
Specificity            0.9945   0.9883   0.9948   0.9909   0.9958
Pos Pred Value         0.9863   0.9508   0.9756   0.9533   0.9815
Neg Pred Value         0.9884   0.9928   0.9885   0.9955   0.9983
Prevalence             0.2889   0.1898   0.1796   0.1599   0.1818
Detection Rate         0.2805   0.1840   0.1701   0.1562   0.1805
Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
Balanced Accuracy      0.9828   0.9789   0.9709   0.9838   0.9942
#################################################################################################################

###Comparing Models
compare <- resamples(list(DTree=modrpart, NeuralNet=modnnet, RandomForest=modrf, SVM=modsvm))
#Summarize Distributions
summary(compare)
#Visualize Results
bwplot(compare)

################################################Model Comparison#################################################
Models: DTree, NeuralNet, RandomForest, SVM 
Number of resamples: 5 

Accuracy 
               Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's
DTree        0.6008  0.6180 0.6217 0.6255  0.6431 0.6437    0
NeuralNet    0.7451  0.7817 0.7865 0.7834  0.7903 0.8136    0
RandomForest 0.9640  0.9690 0.9702 0.9693  0.9712 0.9720    0
SVM          0.9552  0.9611 0.9625 0.9619  0.9640 0.9665    0

Kappa 
               Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's
DTree        0.4876  0.5114 0.5239 0.5249  0.5505 0.5510    0
NeuralNet    0.6773  0.7240 0.7304 0.7260  0.7338 0.7642    0
RandomForest 0.9544  0.9608 0.9623 0.9611  0.9636 0.9645    0
SVM          0.9433  0.9507 0.9525 0.9517  0.9544 0.9576    0

###Preprocessing Test Set
testing1<-(testing[,-c(Kurt,Skew, Max, Min, Amp, Var, Avg, Std)])
testing1<-testing1[,-1] #removing serial number

###Scoring Test Set - Based on Random Forest Model as that has the highest accuracy#############################
testingpc<-predict(trainset2, testing1)
predict(modrf, testingpc)

###Scored Results###############################################################################################
 [1] B A B A A E D B A A B C B A E E A B B B
Levels: A B C D E
